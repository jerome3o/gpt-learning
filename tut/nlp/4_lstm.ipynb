{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following [this tutorial](https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1413835f50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Author: Robert Guthrie\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 3\n",
    "hidden_size = 3\n",
    "sequence_length = 5\n",
    "\n",
    "lstm = nn.LSTM(embedding_dim, hidden_size)\n",
    "inputs = [torch.randn(1, embedding_dim) for _ in range(sequence_length)]\n",
    "\n",
    "hidden = (torch.randn(1, 1, embedding_dim), torch.randn(1, 1, embedding_dim))\n",
    "\n",
    "\n",
    "for i in inputs:\n",
    "    out, hidden = lstm(i.view(1, 1, -1), hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0187,  0.1713, -0.2944]],\n",
      "\n",
      "        [[-0.3521,  0.1026, -0.2971]],\n",
      "\n",
      "        [[-0.3191,  0.0781, -0.1957]],\n",
      "\n",
      "        [[-0.1634,  0.0941, -0.1637]],\n",
      "\n",
      "        [[-0.3368,  0.0959, -0.0538]]], grad_fn=<MkldnnRnnLayerBackward0>)\n",
      "tensor([[[-0.3368,  0.0959, -0.0538]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[-0.9825,  0.4715, -0.0633]]], grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# alternatively, we can do the entire sequence all at once.\n",
    "# the first value returned by LSTM is all of the hidden states throughout\n",
    "# the sequence. the second is just the most recent hidden state\n",
    "# (compare the last slice of \"out\" with \"hidden\" below, they are the same)\n",
    "# The reason for this is that:\n",
    "# \"out\" will give you access to all hidden states in the sequence\n",
    "# \"hidden\" will allow you to continue the sequence and backpropagate,\n",
    "# by passing it as an argument  to the lstm at a later time\n",
    "# Add the extra 2nd dimension\n",
    "inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
    "hidden = (torch.randn(1, 1, 3), torch.randn(1, 1, 3))  # clean out hidden state\n",
    "out, (h_n, c_n) = lstm(inputs, hidden)\n",
    "print(out)\n",
    "print(h_n)\n",
    "print(c_n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM for Part-of-Speech Tagging"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yoinked the UniversalDependencies training data set from [here](https://github.com/UniversalDependencies/UD_English-GUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and testing data\n",
    "\n",
    "from typing import List, Tuple, Callable, Dict\n",
    "import conllu\n",
    "\n",
    "\n",
    "_training_file = \"./data/en_gum-ud-train.conllu\"\n",
    "_testing_file = \"./data/en_gum-ud-test.conllu\"\n",
    "\n",
    "\n",
    "def _load_data(f: str) -> List[Tuple[List[str], List[str]]]:\n",
    "    with open(f) as f:\n",
    "        data = conllu.parse(f.read())\n",
    "\n",
    "    return [\n",
    "        list(zip(\n",
    "            *[(t[\"form\"], t[\"upos\"])\n",
    "            for t in token_list]\n",
    "        ))\n",
    "        for token_list in data\n",
    "    ]\n",
    "\n",
    "training_data = _load_data(_training_file)\n",
    "testing_data = _load_data(_testing_file)\n",
    "\n",
    "# define word_to_idx, tag_to_idx\n",
    "\n",
    "# very memory inefficient, however it's ok because we're only \n",
    "# dealing with a little bit of data\n",
    "vocab = set(\n",
    "    [x for words, _ in training_data for x in words]\n",
    "    + [x for words, _ in testing_data for x in words]\n",
    ")\n",
    "tags = set(\n",
    "    [x for _, tags in training_data for x in tags]\n",
    "    + [x for _, tags in testing_data for x in tags]\n",
    ")\n",
    "chars = set()\n",
    "\n",
    "for words, _ in training_data:\n",
    "    for word in words:\n",
    "        for letter in word:\n",
    "            if not letter.isspace():\n",
    "                chars.add(letter)\n",
    "\n",
    "for words, _ in testing_data:\n",
    "    for word in words:\n",
    "        for letter in word:\n",
    "            if not letter.isspace():\n",
    "                chars.add(letter)\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "tag_count = len(tags)\n",
    "char_count = len(chars)\n",
    "\n",
    "word_to_idx = {w: i for i, w in enumerate(vocab)}\n",
    "tag_to_idx = {t: i for i, t in enumerate(tags)}\n",
    "char_to_idx = {c: i for i, c in enumerate(chars)}\n",
    "\n",
    "\n",
    "def prep_sequence(sent: List[str], to_idx: Callable[[str], int]) -> torch.Tensor:\n",
    "    return torch.tensor(list(map(to_idx.get, sent)), dtype=torch.long)\n",
    "\n",
    "def prep_data(\n",
    "    words: List[str],\n",
    "    tags: List[str],\n",
    "    word_to_idx: Dict[str, int],\n",
    "    tag_to_idx: Dict[str, int],\n",
    "    char_to_idx: Dict[str, int],\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, List[torch.Tensor]]:\n",
    "    word_idx = prep_sequence(words, word_to_idx)\n",
    "    tag_idx = prep_sequence(tags, tag_to_idx)\n",
    "    char_idx_list = [\n",
    "        prep_sequence(list(w), char_to_idx)\n",
    "        for w in words\n",
    "    ]\n",
    "    return word_idx, char_idx_list, tag_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LstmPosTagger(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim: int,\n",
    "        hidden_size: int,\n",
    "        vocab_size: int,\n",
    "        tag_count: int,\n",
    "        char_count: int,\n",
    "        char_embedding_dim: int,\n",
    "        char_hidden_size: int,\n",
    "        num_layers: int = 1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self._embedding_dim = embedding_dim\n",
    "        self._hidden_size = hidden_size\n",
    "        self._vocab_size = vocab_size\n",
    "        self._tag_count = tag_count\n",
    "        self._num_layers = num_layers\n",
    "        self._char_count = char_count\n",
    "        self._char_embedding_dim = char_embedding_dim\n",
    "        self._char_hidden_size = char_hidden_size\n",
    "\n",
    "        self.emb = nn.Embedding(\n",
    "            num_embeddings=self._vocab_size,\n",
    "            embedding_dim=self._embedding_dim,\n",
    "        )\n",
    "\n",
    "        self.char_emb = nn.Embedding(\n",
    "            num_embeddings=self._char_count,\n",
    "            embedding_dim=self._char_embedding_dim,\n",
    "        )\n",
    "\n",
    "        self.char_lstm = nn.LSTM(\n",
    "            input_size=self._char_embedding_dim,\n",
    "            hidden_size=self._char_hidden_size,\n",
    "            num_layers=self._num_layers,\n",
    "        )\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self._embedding_dim + self._char_hidden_size,\n",
    "            hidden_size=self._hidden_size,\n",
    "            num_layers=self._num_layers,\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(\n",
    "            in_features=self._hidden_size,\n",
    "            out_features=self._tag_count,\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,  # (seq_length, batch_size, 1)\n",
    "        x_chars: torch.Tensor,\n",
    "    ):\n",
    "        x = self.emb(x)  # (seq_length, batch_size, emb_dim)\n",
    "\n",
    "        seq_length, _ = x.size()\n",
    "        x_combined = torch.zeros(\n",
    "            (seq_length, self._embedding_dim + self._char_hidden_size),\n",
    "            device=x.device,\n",
    "        )\n",
    "        x_combined[:, :self._embedding_dim] = x\n",
    "\n",
    "        for i, x_word in enumerate(x_chars):\n",
    "            _, (h, _) = self.char_lstm(self.char_emb(x_word))\n",
    "            x_combined[i, self._embedding_dim:] = h[-1]\n",
    "\n",
    "\n",
    "        all_hidden_states, _ = self.lstm(x_combined)\n",
    "        # all_hidden_states (seq_length, batch_size, hidden_size)\n",
    "\n",
    "        output = self.fc(all_hidden_states)  # (seq_length, batch_size, tag_count)\n",
    "        return output\n",
    "\n",
    "\n",
    "def calculate_accuracy(\n",
    "    model: LstmPosTagger,\n",
    "    data: List[Tuple[List[str], List[str]]],\n",
    "    word_to_idx: Dict[str, int],\n",
    "    tag_to_idx: Dict[str, int],\n",
    ") -> float:\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x_raw, tags_raw in data:\n",
    "            x, x_chars, tags = prep_data(\n",
    "                words=x_raw,\n",
    "                tags=tags_raw,\n",
    "                word_to_idx=word_to_idx,\n",
    "                tag_to_idx=tag_to_idx,\n",
    "                char_to_idx=char_to_idx,\n",
    "            )\n",
    "            output = model(x, x_chars)\n",
    "            logits = F.softmax(output, -1)\n",
    "            _, tags_pred = torch.max(logits, dim=-1)\n",
    "            correct += (tags_pred == tags).sum().item()\n",
    "            total += x.size(0)\n",
    "    return correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 30\n",
    "CHAR_EMBEDDING_DIM = 5\n",
    "HIDDEN_SIZE = 40\n",
    "CHAR_HIDDEN_SIZE = 5\n",
    "LEARNING_RATE = 0.01\n",
    "N_EPOCHS = 25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LstmPosTagger(\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    vocab_size=vocab_size,\n",
    "    tag_count=tag_count,\n",
    "    char_count=char_count,\n",
    "    char_embedding_dim=CHAR_EMBEDDING_DIM,\n",
    "    char_hidden_size=CHAR_HIDDEN_SIZE,\n",
    ")\n",
    "loss_function = F.cross_entropy\n",
    "optimiser = optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "n_training_points = len(training_data)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    cum_loss = 0\n",
    "    for x_raw, tags_raw in training_data:\n",
    "        x, x_chars, tags = prep_data(\n",
    "            words=x_raw,\n",
    "            tags=tags_raw,\n",
    "            word_to_idx=word_to_idx,\n",
    "            tag_to_idx=tag_to_idx,\n",
    "            char_to_idx=char_to_idx,\n",
    "        )\n",
    "        optimiser.zero_grad()\n",
    "        tags_pred = model(x, x_chars)\n",
    "        loss = loss_function(tags_pred, tags)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        cum_loss += loss.item()\n",
    "\n",
    "    train_acc = calculate_accuracy(\n",
    "        model,\n",
    "        training_data,\n",
    "        word_to_idx,\n",
    "        tag_to_idx,\n",
    "    )\n",
    "    test_acc = calculate_accuracy(\n",
    "        model,\n",
    "        testing_data,\n",
    "        word_to_idx,\n",
    "        tag_to_idx,\n",
    "    )\n",
    "    print(\n",
    "        f\"epoch: {epoch}, \"\n",
    "        f\"loss: {cum_loss/n_training_points: 0.2f}, \"\n",
    "        f\"test acc: {test_acc:0.2f}, \"\n",
    "        f\"train acc: {train_acc:0.2f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_idx = prep_sequence(x_raw, word_to_idx)\n",
    "x = model.emb(x_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq, _ = x.size()\n",
    "x_comb = torch.zeros((seq, EMBEDDING_DIM + 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb[:, :EMBEDDING_DIM] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
