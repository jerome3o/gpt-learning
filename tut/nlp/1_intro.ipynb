{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following [this tutorial](https://pytorch.org/tutorials/beginner/nlp/pytorch_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f0372fa8f70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6],\n",
      "         [ 7,  8,  9]],\n",
      "\n",
      "        [[10, 11, 12],\n",
      "         [13, 14, 15],\n",
      "         [16, 17, 18]]])\n"
     ]
    }
   ],
   "source": [
    "vector_data = [1, 2, 3]\n",
    "vector = torch.tensor(vector_data)\n",
    "print(vector)\n",
    "\n",
    "matrix_data = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "matrix = torch.tensor(matrix_data)\n",
    "print(matrix)\n",
    "\n",
    "tensor_data = [\n",
    "    [[1, 2, 3], [4, 5, 6], [7, 8, 9]],\n",
    "    [[10, 11, 12], [13, 14, 15], [16, 17, 18]],\n",
    "]\n",
    "tensor = torch.tensor(tensor_data)\n",
    "print(tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n",
      "1\n",
      "tensor([1, 2, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "print(vector[0])\n",
    "print(vector[0].item())\n",
    "\n",
    "print(matrix[0])\n",
    "print(tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.4100,  0.4085,  0.2579,  1.0950, -0.5065],\n",
      "         [ 0.0998, -0.6540,  0.7317, -1.4567,  1.6089],\n",
      "         [ 0.0938, -1.2597,  0.2546, -0.5020, -1.0412],\n",
      "         [ 0.7323,  1.3075, -1.1628,  0.1196, -0.1631]],\n",
      "\n",
      "        [[ 0.6614,  1.1899,  0.8165, -0.9135, -0.3538],\n",
      "         [ 0.7639, -0.5890, -0.7636,  1.3352,  0.6043],\n",
      "         [-0.1034, -0.1512,  1.2466,  0.5057,  0.9505],\n",
      "         [ 1.2966,  0.8738, -0.5603,  1.2858,  0.8168]],\n",
      "\n",
      "        [[-1.4648, -1.2629,  1.1220,  1.5663, -1.0371],\n",
      "         [-1.0669, -0.2085, -0.2155,  0.2705,  0.5597],\n",
      "         [-0.3184,  1.5117, -1.5208,  0.9196, -0.5484],\n",
      "         [-0.3472, -0.7474, -0.9234,  0.5734, -0.1093]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn((3, 4, 5))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1., 2., 3.])\n",
    "y = torch.tensor([4., 5., 6.])\n",
    "z = x + y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-6.9328e-01, -1.6676e-01, -9.9988e-01, -1.6476e+00,  8.0983e-01],\n",
      "        [ 5.5424e-02,  1.1340e+00, -5.3264e-01,  6.5921e-01, -1.5964e+00],\n",
      "        [-3.7687e-01, -3.1020e+00, -9.9467e-02, -7.2126e-01,  1.2708e+00],\n",
      "        [-2.0225e-03, -1.0952e+00,  6.0165e-01,  6.9841e-01, -8.0052e-01],\n",
      "        [ 1.5381e+00,  1.4673e+00,  1.5951e+00, -1.5279e+00,  1.0156e+00]])\n",
      "tensor([[-0.2020, -1.2865,  0.8231,  0.6684,  1.1628, -0.3229,  1.8782, -0.5666],\n",
      "        [-0.6101, -1.2960, -0.9434,  0.4016, -0.1153,  0.3170,  0.5629,  0.8662]])\n"
     ]
    }
   ],
   "source": [
    "# By default, it concatenates along the first axis (concatenates rows)\n",
    "x_1 = torch.randn(2, 5)\n",
    "y_1 = torch.randn(3, 5)\n",
    "z_1 = torch.cat([x_1, y_1])\n",
    "print(z_1)\n",
    "\n",
    "# Concatenate columns:\n",
    "x_2 = torch.randn(2, 3)\n",
    "y_2 = torch.randn(2, 5)\n",
    "# second arg specifies which axis to concat along\n",
    "z_2 = torch.cat([x_2, y_2], 1)\n",
    "print(z_2)\n",
    "\n",
    "# If your tensors are not compatible, torch will complain.  Uncomment to see the error\n",
    "# torch.cat([x_1, x_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2278, -0.8676,  0.3398, -1.1494],\n",
      "         [ 0.6522, -0.8726,  0.0353, -0.3365],\n",
      "         [ 0.7225,  0.1526,  0.1450, -2.3442]],\n",
      "\n",
      "        [[-0.4619, -0.3686,  0.3682,  0.4850],\n",
      "         [ 0.1988,  0.5441, -0.3978, -1.9291],\n",
      "         [ 0.9264,  0.9134, -0.7902, -0.5831]]])\n",
      "tensor([[-0.2278, -0.8676,  0.3398, -1.1494,  0.6522, -0.8726,  0.0353, -0.3365,\n",
      "          0.7225,  0.1526,  0.1450, -2.3442],\n",
      "        [-0.4619, -0.3686,  0.3682,  0.4850,  0.1988,  0.5441, -0.3978, -1.9291,\n",
      "          0.9264,  0.9134, -0.7902, -0.5831]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 4)\n",
    "print(x)\n",
    "print(x.view(2, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0127, -1.8734,  1.7997,  0.2824,  0.2151,  0.9385,  1.4657, -0.5565,\n",
      "          2.4142,  1.0206, -0.4405, -1.7342],\n",
      "        [-1.0257,  0.5213, -0.4531, -0.1260, -0.5882,  2.1189, -0.5422, -2.4593,\n",
      "         -0.9502, -0.3095,  1.6633,  0.5051]])\n"
     ]
    }
   ],
   "source": [
    "print(x.view(2, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# computation graphs and automatic differentiation\n",
    "\n",
    "x = torch.tensor([1., 2., 3.], dtype=torch.float32, requires_grad=True)\n",
    "y = torch.tensor([4., 5., 6.], dtype=torch.float32, requires_grad=True)\n",
    "z = x + y\n",
    "\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x7f03702eb610>\n"
     ]
    }
   ],
   "source": [
    "print(z.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(21., grad_fn=<SumBackward0>)\n",
      "<SumBackward0 object at 0x7f055c409af0>\n"
     ]
    }
   ],
   "source": [
    "s = z.sum()\n",
    "print(s)\n",
    "print(s.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "s.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 2)\n",
    "y = torch.randn(2, 2)\n",
    "# By default, user created Tensors have ``requires_grad=False``\n",
    "print(x.requires_grad, y.requires_grad)\n",
    "z = x + y\n",
    "# So you can't backprop through z\n",
    "print(z.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x7f055c2e6be0>\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# ``.requires_grad_( ... )`` changes an existing Tensor's ``requires_grad``\n",
    "# flag in-place. The input flag defaults to ``True`` if not given.\n",
    "x = x.requires_grad_()\n",
    "y = y.requires_grad_()\n",
    "# z contains enough information to compute gradients, as we saw above\n",
    "z = x + y\n",
    "print(z.grad_fn)\n",
    "# If any input to an operation has ``requires_grad=True``, so will the output\n",
    "print(z.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now z has the computation history that relates itself to x and y\n",
    "# Can we just take its values, and **detach** it from its history?\n",
    "new_z = z.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ... does new_z have information to backprop to x and y?\n",
    "# NO!\n",
    "print(new_z.grad_fn)\n",
    "# And how could it? ``z.detach()`` returns a tensor that shares the same storage\n",
    "# as ``z``, but with the computation history forgotten. It doesn't know anything\n",
    "# about how it was computed.\n",
    "# In essence, we have broken the Tensor away from its past history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "print((x ** 2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
