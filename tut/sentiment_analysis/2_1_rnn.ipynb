{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e3a6cb3-d272-44ec-a666-ed634b9486f1",
   "metadata": {},
   "source": [
    "# Building a Deep Neural Net for Sentiment Analysis on IMDb Reviews\n",
    "\n",
    "## 1. Data collection and preprocessing\n",
    "- Collect a dataset of IMDb reviews\n",
    "- Preprocess the text data (tokenization, lowercasing, removing special characters, etc.)\n",
    "- Split the dataset into training, validation, and test sets\n",
    "\n",
    "## 2. **Model selection and architecture**\n",
    "- Research different types of deep learning models (**RNN**, LSTM, GRU, CNN, Transformer)\n",
    "- Decide on a model architecture\n",
    "- Experiment with pre-trained models (BERT, GPT, RoBERTa) for fine-tuning\n",
    "\n",
    "## 3. Model training and hyperparameter tuning\n",
    "- Set up a training loop\n",
    "- Use backpropagation to update the model's weights based on the loss function\n",
    "- Experiment with different hyperparameters (learning rate, batch size, dropout rate, etc.) and optimization algorithms (Adam, RMSprop, etc.)\n",
    "- Monitor performance on the validation set during training\n",
    "\n",
    "## 4. Model evaluation and refinement\n",
    "- Evaluate the model on the test set using relevant metrics (accuracy, F1 score, precision, recall, etc.)\n",
    "- Identify areas for improvement and iterate on the model architecture, training process, or preprocessing techniques\n",
    "\n",
    "## 5. \"Extra for experts\" ideas\n",
    "- Handle class imbalance (oversampling, undersampling, or SMOTE)\n",
    "- Experiment with different word embeddings (Word2Vec, GloVe, FastText) or contextual embeddings (ELMo, BERT)\n",
    "- Explore advanced model architectures (multi-head attention, capsule networks, memory-augmented networks)\n",
    "- Investigate transfer learning or multi-task learning\n",
    "- Conduct error analysis to understand and address specific issues\n",
    "- Develop a user interface or API for your sentiment analysis model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4e9b2ba-e5d6-453c-aea1-d445c4249e61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import tokenizers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "class JeromeRNNInnerModule(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        hidden_size: int,\n",
    "        activation_function=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._activation = activation_function or F.tanh\n",
    "        self._input_size = input_size\n",
    "        self._hidden_size = hidden_size\n",
    "\n",
    "        # use Xavier initialisation to avoid exploding exponentials\n",
    "        self._w_ax = nn.Parameter(torch.Tensor(self._input_size + self._hidden_size, self._hidden_size))\n",
    "        nn.init.kaiming_uniform_(self._w_ax)\n",
    "\n",
    "        # bias\n",
    "        self._b_ax = nn.Parameter(torch.zeros(self._hidden_size))\n",
    "\n",
    "    def forward(self, x, a):\n",
    "        # single token\n",
    "        # x shape is (L, B, _input_size)\n",
    "\n",
    "        L, B, _ = x.size()\n",
    "        output = torch.zeros((L, B, self._hidden_size), device=x.device)\n",
    "\n",
    "        for t in range(L):\n",
    "            x_t = x[t]\n",
    "            a = self._activation(\n",
    "                torch.matmul(\n",
    "                    torch.concat((x_t, a), dim=-1),\n",
    "                    self._w_ax\n",
    "                ) + self._b_ax\n",
    "            )\n",
    "            output[t, :, :] = a\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "class JeromeRNNBlockModule(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        hidden_size: int,\n",
    "        n_layers: int,\n",
    "        activation_function=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._hidden_size = hidden_size\n",
    "        self._input_size = input_size\n",
    "        self._layers = nn.ModuleList([\n",
    "            JeromeRNNInnerModule(\n",
    "                input_size=input_size if i == 0 else hidden_size,\n",
    "                hidden_size=hidden_size,\n",
    "                activation_function=activation_function,\n",
    "            )\n",
    "            for i in range(n_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x shape: (L, B, _input_size)\n",
    "        _, batch_size, _ = x.size()\n",
    "\n",
    "        for i, layer in enumerate(self._layers):\n",
    "            a = torch.zeros((batch_size, self._hidden_size), device=x.device)\n",
    "            x = layer(x, a)\n",
    "        \n",
    "        return x[-1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SentimentAnalysisModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        emb_dim: int = 30,\n",
    "        hidden_size: int = 40,\n",
    "        n_rnn_layers: int = 1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=emb_dim,\n",
    "        )\n",
    "        # self.rnn = nn.RNN(\n",
    "        #     input_size=emb_dim,\n",
    "        #     hidden_size=hidden_size,\n",
    "        #     num_layers=n_rnn_layers,\n",
    "        # )\n",
    "\n",
    "        # Using Jerome's RNN\n",
    "        self.rnn = JeromeRNNBlockModule(\n",
    "            input_size=emb_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            n_layers=n_rnn_layers,\n",
    "        )\n",
    "\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, 2),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, lengths: torch.Tensor):\n",
    "        # x shape: (B, L)\n",
    "        # convert token indices to embedding values\n",
    "        x = self.emb(x)\n",
    "        # x shape: (B, L, Emb dim)\n",
    "\n",
    "        x = x.transpose(0, 1)\n",
    "        # x shape: (L, B, Emb dim)\n",
    "\n",
    "        # # pack the sequence\n",
    "        # x = pack_padded_sequence(x, lengths, enforce_sorted=False)\n",
    "\n",
    "        # # run the rnn, only taking the final rnn hidden state from the last layer\n",
    "        # # TODO: understand the difference between the two outputs more\n",
    "        # _, x = self.rnn(x)\n",
    "        # # x shape: (B, n_rnn_layers, Hidden size?)\n",
    "        \n",
    "        # # take only the last layer\n",
    "        # x = x[-1, :, :]\n",
    "\n",
    "        # Using Jerome's RNN\n",
    "        x = self.rnn(x)\n",
    "\n",
    "        # x shape: (B, Hidden size?)\n",
    "        \n",
    "        return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37b1b78a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load in tokenized data\n",
    "data_dict = torch.load(\"data/imdb_data.pt\")\n",
    "data = data_dict[\"reviews\"]\n",
    "labels = data_dict[\"labels\"]\n",
    "lengths = data_dict[\"lengths\"]\n",
    "\n",
    "# split into train and test by 80:20\n",
    "training_fraction = 0.8\n",
    "\n",
    "train_data = data[:int(len(data) * training_fraction)]\n",
    "train_labels = labels[:int(len(data) * training_fraction)]\n",
    "train_lengths = lengths[:int(len(data) * training_fraction)]\n",
    "\n",
    "test_data = data[int(len(data) * training_fraction):]\n",
    "test_labels = labels[int(len(data) * training_fraction):]\n",
    "test_lengths = lengths[int(len(data) * training_fraction):]\n",
    "\n",
    "\n",
    "# load in tokenizer\n",
    "tokenizer = tokenizers.Tokenizer.from_file(\"models/tokenizer.json\")\n",
    "vocab_size = tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885a232e",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6adca516",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(\n",
    "    model: nn.Module,\n",
    "    train_data: torch.Tensor,\n",
    "    train_labels: torch.Tensor,\n",
    "    train_lengths: torch.Tensor,\n",
    "    batch_size: int,\n",
    "):\n",
    "    # calculate overall loss (need batching for memory reasons)\n",
    "    loss = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(train_data), batch_size):\n",
    "            training_data_batch = train_data[i : i + batch_size]\n",
    "            training_labels_batch = train_labels[i : i + batch_size]\n",
    "            training_lengths_batch = train_lengths[i : i + batch_size]\n",
    "\n",
    "            output = model(training_data_batch, lengths=training_lengths_batch)\n",
    "            ## Calculate correct predictions\n",
    "            _, y_predicted = torch.max(output, 1)\n",
    "            total += training_labels_batch.size(0)\n",
    "            correct += (y_predicted == training_labels_batch).sum().item()\n",
    "            loss += nn.functional.cross_entropy(output, training_labels_batch)\n",
    "\n",
    "    return loss, correct, total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb64173b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDATE - Epoch: 0, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 0, Loss: 2.26\n",
      "UPDATE - Epoch: 1, Train Acc: 50.91% (loss: 2.09), Test Acc:  50.39% (loss: 2.09)\n",
      "Epoch: 1, Loss: 2.09\n",
      "UPDATE - Epoch: 2, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.09)\n",
      "Epoch: 2, Loss: 2.09\n",
      "UPDATE - Epoch: 3, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 3, Loss: 2.08\n",
      "UPDATE - Epoch: 4, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 4, Loss: 2.08\n",
      "UPDATE - Epoch: 5, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 5, Loss: 2.08\n",
      "UPDATE - Epoch: 6, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 6, Loss: 2.08\n",
      "UPDATE - Epoch: 7, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 7, Loss: 2.08\n",
      "UPDATE - Epoch: 8, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 8, Loss: 2.08\n",
      "UPDATE - Epoch: 9, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 9, Loss: 2.08\n",
      "UPDATE - Epoch: 10, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 10, Loss: 2.08\n",
      "UPDATE - Epoch: 11, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 11, Loss: 2.08\n",
      "UPDATE - Epoch: 12, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 12, Loss: 2.08\n",
      "UPDATE - Epoch: 13, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 13, Loss: 2.08\n",
      "UPDATE - Epoch: 14, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 14, Loss: 2.08\n",
      "UPDATE - Epoch: 15, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 15, Loss: 2.08\n",
      "UPDATE - Epoch: 16, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 16, Loss: 2.08\n",
      "UPDATE - Epoch: 17, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 17, Loss: 2.08\n",
      "UPDATE - Epoch: 18, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 18, Loss: 2.08\n",
      "UPDATE - Epoch: 19, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 19, Loss: 2.08\n",
      "UPDATE - Epoch: 20, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 20, Loss: 2.08\n",
      "UPDATE - Epoch: 21, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 21, Loss: 2.08\n",
      "UPDATE - Epoch: 22, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 22, Loss: 2.08\n",
      "UPDATE - Epoch: 23, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 23, Loss: 2.08\n",
      "UPDATE - Epoch: 24, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 24, Loss: 2.08\n",
      "UPDATE - Epoch: 25, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 25, Loss: 2.08\n",
      "UPDATE - Epoch: 26, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 26, Loss: 2.08\n",
      "UPDATE - Epoch: 27, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 27, Loss: 2.08\n",
      "UPDATE - Epoch: 28, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 28, Loss: 2.08\n",
      "UPDATE - Epoch: 29, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 29, Loss: 2.08\n",
      "UPDATE - Epoch: 30, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 30, Loss: 2.08\n",
      "UPDATE - Epoch: 31, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 31, Loss: 2.08\n",
      "UPDATE - Epoch: 32, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 32, Loss: 2.08\n",
      "UPDATE - Epoch: 33, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 33, Loss: 2.08\n",
      "UPDATE - Epoch: 34, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 34, Loss: 2.08\n",
      "UPDATE - Epoch: 35, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 35, Loss: 2.08\n",
      "UPDATE - Epoch: 36, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 36, Loss: 2.08\n",
      "UPDATE - Epoch: 37, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 37, Loss: 2.08\n",
      "UPDATE - Epoch: 38, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 38, Loss: 2.08\n",
      "UPDATE - Epoch: 39, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 39, Loss: 2.08\n",
      "UPDATE - Epoch: 40, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 40, Loss: 2.08\n",
      "UPDATE - Epoch: 41, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 41, Loss: 2.08\n",
      "UPDATE - Epoch: 42, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 42, Loss: 2.08\n",
      "UPDATE - Epoch: 43, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 43, Loss: 2.08\n",
      "UPDATE - Epoch: 44, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 44, Loss: 2.08\n",
      "UPDATE - Epoch: 45, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 45, Loss: 2.08\n",
      "UPDATE - Epoch: 46, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 46, Loss: 2.08\n",
      "UPDATE - Epoch: 47, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 47, Loss: 2.08\n",
      "UPDATE - Epoch: 48, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 48, Loss: 2.08\n",
      "UPDATE - Epoch: 49, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 49, Loss: 2.08\n",
      "UPDATE - Epoch: 50, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 50, Loss: 2.08\n",
      "UPDATE - Epoch: 51, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 51, Loss: 2.08\n",
      "UPDATE - Epoch: 52, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 52, Loss: 2.08\n",
      "UPDATE - Epoch: 53, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 53, Loss: 2.08\n",
      "UPDATE - Epoch: 54, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 54, Loss: 2.08\n",
      "UPDATE - Epoch: 55, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 55, Loss: 2.08\n",
      "UPDATE - Epoch: 56, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 56, Loss: 2.08\n",
      "UPDATE - Epoch: 57, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 57, Loss: 2.08\n",
      "UPDATE - Epoch: 58, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 58, Loss: 2.08\n",
      "UPDATE - Epoch: 59, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 59, Loss: 2.08\n",
      "UPDATE - Epoch: 60, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 60, Loss: 2.08\n",
      "UPDATE - Epoch: 61, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 61, Loss: 2.08\n",
      "UPDATE - Epoch: 62, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 62, Loss: 2.08\n",
      "UPDATE - Epoch: 63, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 63, Loss: 2.08\n",
      "UPDATE - Epoch: 64, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 64, Loss: 2.08\n",
      "UPDATE - Epoch: 65, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 65, Loss: 2.08\n",
      "UPDATE - Epoch: 66, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 66, Loss: 2.08\n",
      "UPDATE - Epoch: 67, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 67, Loss: 2.08\n",
      "UPDATE - Epoch: 68, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 68, Loss: 2.08\n",
      "UPDATE - Epoch: 69, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 69, Loss: 2.08\n",
      "UPDATE - Epoch: 70, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 70, Loss: 2.08\n",
      "UPDATE - Epoch: 71, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 71, Loss: 2.08\n",
      "UPDATE - Epoch: 72, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 72, Loss: 2.08\n",
      "UPDATE - Epoch: 73, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 73, Loss: 2.08\n",
      "UPDATE - Epoch: 74, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 74, Loss: 2.08\n",
      "UPDATE - Epoch: 75, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 75, Loss: 2.08\n",
      "UPDATE - Epoch: 76, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 76, Loss: 2.08\n",
      "UPDATE - Epoch: 77, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 77, Loss: 2.08\n",
      "UPDATE - Epoch: 78, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 78, Loss: 2.08\n",
      "UPDATE - Epoch: 79, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 79, Loss: 2.08\n",
      "UPDATE - Epoch: 80, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 80, Loss: 2.08\n",
      "UPDATE - Epoch: 81, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 81, Loss: 2.08\n",
      "UPDATE - Epoch: 82, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 82, Loss: 2.08\n",
      "UPDATE - Epoch: 83, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 83, Loss: 2.08\n",
      "UPDATE - Epoch: 84, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 84, Loss: 2.08\n",
      "UPDATE - Epoch: 85, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 85, Loss: 2.08\n",
      "UPDATE - Epoch: 86, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 86, Loss: 2.08\n",
      "UPDATE - Epoch: 87, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 87, Loss: 2.08\n",
      "UPDATE - Epoch: 88, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 88, Loss: 2.08\n",
      "UPDATE - Epoch: 89, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 89, Loss: 2.08\n",
      "UPDATE - Epoch: 90, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 90, Loss: 2.08\n",
      "UPDATE - Epoch: 91, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 91, Loss: 2.08\n",
      "UPDATE - Epoch: 92, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 92, Loss: 2.08\n",
      "UPDATE - Epoch: 93, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 93, Loss: 2.08\n",
      "UPDATE - Epoch: 94, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 94, Loss: 2.08\n",
      "UPDATE - Epoch: 95, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 95, Loss: 2.08\n",
      "UPDATE - Epoch: 96, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 96, Loss: 2.08\n",
      "UPDATE - Epoch: 97, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 97, Loss: 2.08\n",
      "UPDATE - Epoch: 98, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 98, Loss: 2.08\n",
      "UPDATE - Epoch: 99, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 99, Loss: 2.08\n",
      "UPDATE - Epoch: 100, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 100, Loss: 2.08\n",
      "UPDATE - Epoch: 101, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 101, Loss: 2.08\n",
      "UPDATE - Epoch: 102, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 102, Loss: 2.08\n",
      "UPDATE - Epoch: 103, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 103, Loss: 2.08\n",
      "UPDATE - Epoch: 104, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 104, Loss: 2.08\n",
      "UPDATE - Epoch: 105, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 105, Loss: 2.08\n",
      "UPDATE - Epoch: 106, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 106, Loss: 2.08\n",
      "UPDATE - Epoch: 107, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 107, Loss: 2.08\n",
      "UPDATE - Epoch: 108, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 108, Loss: 2.08\n",
      "UPDATE - Epoch: 109, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 109, Loss: 2.08\n",
      "UPDATE - Epoch: 110, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 110, Loss: 2.08\n",
      "UPDATE - Epoch: 111, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 111, Loss: 2.08\n",
      "UPDATE - Epoch: 112, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 112, Loss: 2.08\n",
      "UPDATE - Epoch: 113, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 113, Loss: 2.08\n",
      "UPDATE - Epoch: 114, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 114, Loss: 2.08\n",
      "UPDATE - Epoch: 115, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 115, Loss: 2.08\n",
      "UPDATE - Epoch: 116, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 116, Loss: 2.08\n",
      "UPDATE - Epoch: 117, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 117, Loss: 2.08\n",
      "UPDATE - Epoch: 118, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 118, Loss: 2.08\n",
      "UPDATE - Epoch: 119, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 119, Loss: 2.08\n",
      "UPDATE - Epoch: 120, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 120, Loss: 2.08\n",
      "UPDATE - Epoch: 121, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 121, Loss: 2.08\n",
      "UPDATE - Epoch: 122, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 122, Loss: 2.08\n",
      "UPDATE - Epoch: 123, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 123, Loss: 2.08\n",
      "UPDATE - Epoch: 124, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 124, Loss: 2.08\n",
      "UPDATE - Epoch: 125, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 125, Loss: 2.08\n",
      "UPDATE - Epoch: 126, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 126, Loss: 2.08\n",
      "UPDATE - Epoch: 127, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 127, Loss: 2.08\n",
      "UPDATE - Epoch: 128, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 128, Loss: 2.08\n",
      "UPDATE - Epoch: 129, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 129, Loss: 2.08\n",
      "UPDATE - Epoch: 130, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 130, Loss: 2.08\n",
      "UPDATE - Epoch: 131, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 131, Loss: 2.08\n",
      "UPDATE - Epoch: 132, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 132, Loss: 2.08\n",
      "UPDATE - Epoch: 133, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 133, Loss: 2.08\n",
      "UPDATE - Epoch: 134, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 134, Loss: 2.08\n",
      "UPDATE - Epoch: 135, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 135, Loss: 2.08\n",
      "UPDATE - Epoch: 136, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 136, Loss: 2.08\n",
      "UPDATE - Epoch: 137, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 137, Loss: 2.08\n",
      "UPDATE - Epoch: 138, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 138, Loss: 2.08\n",
      "UPDATE - Epoch: 139, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 139, Loss: 2.08\n",
      "UPDATE - Epoch: 140, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 140, Loss: 2.08\n",
      "UPDATE - Epoch: 141, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 141, Loss: 2.08\n",
      "UPDATE - Epoch: 142, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 142, Loss: 2.08\n",
      "UPDATE - Epoch: 143, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 143, Loss: 2.08\n",
      "UPDATE - Epoch: 144, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 144, Loss: 2.08\n",
      "UPDATE - Epoch: 145, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 145, Loss: 2.08\n",
      "UPDATE - Epoch: 146, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 146, Loss: 2.08\n",
      "UPDATE - Epoch: 147, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 147, Loss: 2.08\n",
      "UPDATE - Epoch: 148, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 148, Loss: 2.08\n",
      "UPDATE - Epoch: 149, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 149, Loss: 2.08\n",
      "UPDATE - Epoch: 150, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 150, Loss: 2.08\n",
      "UPDATE - Epoch: 151, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 151, Loss: 2.08\n",
      "UPDATE - Epoch: 152, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 152, Loss: 2.08\n",
      "UPDATE - Epoch: 153, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 153, Loss: 2.08\n",
      "UPDATE - Epoch: 154, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 154, Loss: 2.08\n",
      "UPDATE - Epoch: 155, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 155, Loss: 2.08\n",
      "UPDATE - Epoch: 156, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 156, Loss: 2.08\n",
      "UPDATE - Epoch: 157, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 157, Loss: 2.08\n",
      "UPDATE - Epoch: 158, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 158, Loss: 2.08\n",
      "UPDATE - Epoch: 159, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 159, Loss: 2.08\n",
      "UPDATE - Epoch: 160, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 160, Loss: 2.08\n",
      "UPDATE - Epoch: 161, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 161, Loss: 2.08\n",
      "UPDATE - Epoch: 162, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 162, Loss: 2.08\n",
      "UPDATE - Epoch: 163, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 163, Loss: 2.08\n",
      "UPDATE - Epoch: 164, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 164, Loss: 2.08\n",
      "UPDATE - Epoch: 165, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 165, Loss: 2.08\n",
      "UPDATE - Epoch: 166, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 166, Loss: 2.08\n",
      "UPDATE - Epoch: 167, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 167, Loss: 2.08\n",
      "UPDATE - Epoch: 168, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 168, Loss: 2.08\n",
      "UPDATE - Epoch: 169, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 169, Loss: 2.08\n",
      "UPDATE - Epoch: 170, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 170, Loss: 2.08\n",
      "UPDATE - Epoch: 171, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 171, Loss: 2.08\n",
      "UPDATE - Epoch: 172, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 172, Loss: 2.08\n",
      "UPDATE - Epoch: 173, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 173, Loss: 2.08\n",
      "UPDATE - Epoch: 174, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 174, Loss: 2.08\n",
      "UPDATE - Epoch: 175, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 175, Loss: 2.08\n",
      "UPDATE - Epoch: 176, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 176, Loss: 2.08\n",
      "UPDATE - Epoch: 177, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 177, Loss: 2.08\n",
      "UPDATE - Epoch: 178, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 178, Loss: 2.08\n",
      "UPDATE - Epoch: 179, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 179, Loss: 2.08\n",
      "UPDATE - Epoch: 180, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 180, Loss: 2.08\n",
      "UPDATE - Epoch: 181, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 181, Loss: 2.08\n",
      "UPDATE - Epoch: 182, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 182, Loss: 2.08\n",
      "UPDATE - Epoch: 183, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 183, Loss: 2.08\n",
      "UPDATE - Epoch: 184, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 184, Loss: 2.08\n",
      "UPDATE - Epoch: 185, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 185, Loss: 2.08\n",
      "UPDATE - Epoch: 186, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 186, Loss: 2.08\n",
      "UPDATE - Epoch: 187, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 187, Loss: 2.08\n",
      "UPDATE - Epoch: 188, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 188, Loss: 2.08\n",
      "UPDATE - Epoch: 189, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 189, Loss: 2.08\n",
      "UPDATE - Epoch: 190, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 190, Loss: 2.08\n",
      "UPDATE - Epoch: 191, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 191, Loss: 2.08\n",
      "UPDATE - Epoch: 192, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 192, Loss: 2.08\n",
      "UPDATE - Epoch: 193, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 193, Loss: 2.08\n",
      "UPDATE - Epoch: 194, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 194, Loss: 2.08\n",
      "UPDATE - Epoch: 195, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 195, Loss: 2.08\n",
      "UPDATE - Epoch: 196, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 196, Loss: 2.08\n",
      "UPDATE - Epoch: 197, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 197, Loss: 2.08\n",
      "UPDATE - Epoch: 198, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 198, Loss: 2.08\n",
      "UPDATE - Epoch: 199, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 199, Loss: 2.08\n",
      "UPDATE - Epoch: 200, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 200, Loss: 2.08\n",
      "UPDATE - Epoch: 201, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 201, Loss: 2.08\n",
      "UPDATE - Epoch: 202, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 202, Loss: 2.08\n",
      "UPDATE - Epoch: 203, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 203, Loss: 2.08\n",
      "UPDATE - Epoch: 204, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 204, Loss: 2.08\n",
      "UPDATE - Epoch: 205, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 205, Loss: 2.08\n",
      "UPDATE - Epoch: 206, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 206, Loss: 2.08\n",
      "UPDATE - Epoch: 207, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 207, Loss: 2.08\n",
      "UPDATE - Epoch: 208, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 208, Loss: 2.08\n",
      "UPDATE - Epoch: 209, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 209, Loss: 2.08\n",
      "UPDATE - Epoch: 210, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 210, Loss: 2.08\n",
      "UPDATE - Epoch: 211, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 211, Loss: 2.08\n",
      "UPDATE - Epoch: 212, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 212, Loss: 2.08\n",
      "UPDATE - Epoch: 213, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 213, Loss: 2.08\n",
      "UPDATE - Epoch: 214, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 214, Loss: 2.08\n",
      "UPDATE - Epoch: 215, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 215, Loss: 2.08\n",
      "UPDATE - Epoch: 216, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 216, Loss: 2.08\n",
      "UPDATE - Epoch: 217, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 217, Loss: 2.08\n",
      "UPDATE - Epoch: 218, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 218, Loss: 2.08\n",
      "UPDATE - Epoch: 219, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 219, Loss: 2.08\n",
      "UPDATE - Epoch: 220, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 220, Loss: 2.08\n",
      "UPDATE - Epoch: 221, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 221, Loss: 2.08\n",
      "UPDATE - Epoch: 222, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 222, Loss: 2.08\n",
      "UPDATE - Epoch: 223, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 223, Loss: 2.08\n",
      "UPDATE - Epoch: 224, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 224, Loss: 2.08\n",
      "UPDATE - Epoch: 225, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 225, Loss: 2.08\n",
      "UPDATE - Epoch: 226, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 226, Loss: 2.08\n",
      "UPDATE - Epoch: 227, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 227, Loss: 2.08\n",
      "UPDATE - Epoch: 228, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 228, Loss: 2.08\n",
      "UPDATE - Epoch: 229, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 229, Loss: 2.08\n",
      "UPDATE - Epoch: 230, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 230, Loss: 2.08\n",
      "UPDATE - Epoch: 231, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 231, Loss: 2.08\n",
      "UPDATE - Epoch: 232, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 232, Loss: 2.08\n",
      "UPDATE - Epoch: 233, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 233, Loss: 2.08\n",
      "UPDATE - Epoch: 234, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 234, Loss: 2.08\n",
      "UPDATE - Epoch: 235, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 235, Loss: 2.08\n",
      "UPDATE - Epoch: 236, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 236, Loss: 2.08\n",
      "UPDATE - Epoch: 237, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 237, Loss: 2.08\n",
      "UPDATE - Epoch: 238, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 238, Loss: 2.08\n",
      "UPDATE - Epoch: 239, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 239, Loss: 2.08\n",
      "UPDATE - Epoch: 240, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 240, Loss: 2.08\n",
      "UPDATE - Epoch: 241, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 241, Loss: 2.08\n",
      "UPDATE - Epoch: 242, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 242, Loss: 2.08\n",
      "UPDATE - Epoch: 243, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 243, Loss: 2.08\n",
      "UPDATE - Epoch: 244, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 244, Loss: 2.08\n",
      "UPDATE - Epoch: 245, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 245, Loss: 2.08\n",
      "UPDATE - Epoch: 246, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 246, Loss: 2.08\n",
      "UPDATE - Epoch: 247, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 247, Loss: 2.08\n",
      "UPDATE - Epoch: 248, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 248, Loss: 2.08\n",
      "UPDATE - Epoch: 249, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 249, Loss: 2.08\n",
      "UPDATE - Epoch: 250, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 250, Loss: 2.08\n",
      "UPDATE - Epoch: 251, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 251, Loss: 2.08\n",
      "UPDATE - Epoch: 252, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 252, Loss: 2.08\n",
      "UPDATE - Epoch: 253, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 253, Loss: 2.08\n",
      "UPDATE - Epoch: 254, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 254, Loss: 2.08\n",
      "UPDATE - Epoch: 255, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 255, Loss: 2.08\n",
      "UPDATE - Epoch: 256, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 256, Loss: 2.08\n",
      "UPDATE - Epoch: 257, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 257, Loss: 2.08\n",
      "UPDATE - Epoch: 258, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 258, Loss: 2.08\n",
      "UPDATE - Epoch: 259, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 259, Loss: 2.08\n",
      "UPDATE - Epoch: 260, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 260, Loss: 2.08\n",
      "UPDATE - Epoch: 261, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 261, Loss: 2.08\n",
      "UPDATE - Epoch: 262, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 262, Loss: 2.08\n",
      "UPDATE - Epoch: 263, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 263, Loss: 2.08\n",
      "UPDATE - Epoch: 264, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 264, Loss: 2.08\n",
      "UPDATE - Epoch: 265, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 265, Loss: 2.08\n",
      "UPDATE - Epoch: 266, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 266, Loss: 2.08\n",
      "UPDATE - Epoch: 267, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 267, Loss: 2.08\n",
      "UPDATE - Epoch: 268, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 268, Loss: 2.08\n",
      "UPDATE - Epoch: 269, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 269, Loss: 2.08\n",
      "UPDATE - Epoch: 270, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 270, Loss: 2.08\n",
      "UPDATE - Epoch: 271, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 271, Loss: 2.08\n",
      "UPDATE - Epoch: 272, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 272, Loss: 2.08\n",
      "UPDATE - Epoch: 273, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 273, Loss: 2.08\n",
      "UPDATE - Epoch: 274, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 274, Loss: 2.08\n",
      "UPDATE - Epoch: 275, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 275, Loss: 2.08\n",
      "UPDATE - Epoch: 276, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 276, Loss: 2.08\n",
      "UPDATE - Epoch: 277, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 277, Loss: 2.08\n",
      "UPDATE - Epoch: 278, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 278, Loss: 2.08\n",
      "UPDATE - Epoch: 279, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 279, Loss: 2.08\n",
      "UPDATE - Epoch: 280, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 280, Loss: 2.08\n",
      "UPDATE - Epoch: 281, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 281, Loss: 2.08\n",
      "UPDATE - Epoch: 282, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 282, Loss: 2.08\n",
      "UPDATE - Epoch: 283, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 283, Loss: 2.08\n",
      "UPDATE - Epoch: 284, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 284, Loss: 2.08\n",
      "UPDATE - Epoch: 285, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 285, Loss: 2.08\n",
      "UPDATE - Epoch: 286, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 286, Loss: 2.08\n",
      "UPDATE - Epoch: 287, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 287, Loss: 2.08\n",
      "UPDATE - Epoch: 288, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 288, Loss: 2.08\n",
      "UPDATE - Epoch: 289, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 289, Loss: 2.08\n",
      "UPDATE - Epoch: 290, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 290, Loss: 2.08\n",
      "UPDATE - Epoch: 291, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 291, Loss: 2.08\n",
      "UPDATE - Epoch: 292, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 292, Loss: 2.08\n",
      "UPDATE - Epoch: 293, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 293, Loss: 2.08\n",
      "UPDATE - Epoch: 294, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 294, Loss: 2.08\n",
      "UPDATE - Epoch: 295, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 295, Loss: 2.08\n",
      "UPDATE - Epoch: 296, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 296, Loss: 2.08\n",
      "UPDATE - Epoch: 297, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 297, Loss: 2.08\n",
      "UPDATE - Epoch: 298, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 298, Loss: 2.08\n",
      "UPDATE - Epoch: 299, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 299, Loss: 2.08\n",
      "UPDATE - Epoch: 300, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 300, Loss: 2.08\n",
      "UPDATE - Epoch: 301, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 301, Loss: 2.08\n",
      "UPDATE - Epoch: 302, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 302, Loss: 2.08\n",
      "UPDATE - Epoch: 303, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 303, Loss: 2.08\n",
      "UPDATE - Epoch: 304, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 304, Loss: 2.08\n",
      "UPDATE - Epoch: 305, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 305, Loss: 2.08\n",
      "UPDATE - Epoch: 306, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 306, Loss: 2.08\n",
      "UPDATE - Epoch: 307, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 307, Loss: 2.08\n",
      "UPDATE - Epoch: 308, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 308, Loss: 2.08\n",
      "UPDATE - Epoch: 309, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 309, Loss: 2.08\n",
      "UPDATE - Epoch: 310, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 310, Loss: 2.08\n",
      "UPDATE - Epoch: 311, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 311, Loss: 2.08\n",
      "UPDATE - Epoch: 312, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 312, Loss: 2.08\n",
      "UPDATE - Epoch: 313, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 313, Loss: 2.08\n",
      "UPDATE - Epoch: 314, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 314, Loss: 2.08\n",
      "UPDATE - Epoch: 315, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 315, Loss: 2.08\n",
      "UPDATE - Epoch: 316, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 316, Loss: 2.08\n",
      "UPDATE - Epoch: 317, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 317, Loss: 2.08\n",
      "UPDATE - Epoch: 318, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 318, Loss: 2.08\n",
      "UPDATE - Epoch: 319, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 319, Loss: 2.08\n",
      "UPDATE - Epoch: 320, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 320, Loss: 2.08\n",
      "UPDATE - Epoch: 321, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 321, Loss: 2.08\n",
      "UPDATE - Epoch: 322, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 322, Loss: 2.08\n",
      "UPDATE - Epoch: 323, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 323, Loss: 2.08\n",
      "UPDATE - Epoch: 324, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 324, Loss: 2.08\n",
      "UPDATE - Epoch: 325, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 325, Loss: 2.08\n",
      "UPDATE - Epoch: 326, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 326, Loss: 2.08\n",
      "UPDATE - Epoch: 327, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 327, Loss: 2.08\n",
      "UPDATE - Epoch: 328, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 328, Loss: 2.08\n",
      "UPDATE - Epoch: 329, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 329, Loss: 2.08\n",
      "UPDATE - Epoch: 330, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 330, Loss: 2.08\n",
      "UPDATE - Epoch: 331, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 331, Loss: 2.08\n",
      "UPDATE - Epoch: 332, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 332, Loss: 2.08\n",
      "UPDATE - Epoch: 333, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 333, Loss: 2.08\n",
      "UPDATE - Epoch: 334, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 334, Loss: 2.08\n",
      "UPDATE - Epoch: 335, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 335, Loss: 2.08\n",
      "UPDATE - Epoch: 336, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 336, Loss: 2.08\n",
      "UPDATE - Epoch: 337, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 337, Loss: 2.08\n",
      "UPDATE - Epoch: 338, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 338, Loss: 2.08\n",
      "UPDATE - Epoch: 339, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 339, Loss: 2.08\n",
      "UPDATE - Epoch: 340, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 340, Loss: 2.08\n",
      "UPDATE - Epoch: 341, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 341, Loss: 2.08\n",
      "UPDATE - Epoch: 342, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 342, Loss: 2.08\n",
      "UPDATE - Epoch: 343, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 343, Loss: 2.08\n",
      "UPDATE - Epoch: 344, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 344, Loss: 2.08\n",
      "UPDATE - Epoch: 345, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 345, Loss: 2.08\n",
      "UPDATE - Epoch: 346, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 346, Loss: 2.08\n",
      "UPDATE - Epoch: 347, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 347, Loss: 2.08\n",
      "UPDATE - Epoch: 348, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 348, Loss: 2.08\n",
      "UPDATE - Epoch: 349, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 349, Loss: 2.08\n",
      "UPDATE - Epoch: 350, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 350, Loss: 2.08\n",
      "UPDATE - Epoch: 351, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 351, Loss: 2.08\n",
      "UPDATE - Epoch: 352, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 352, Loss: 2.08\n",
      "UPDATE - Epoch: 353, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 353, Loss: 2.08\n",
      "UPDATE - Epoch: 354, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 354, Loss: 2.08\n",
      "UPDATE - Epoch: 355, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 355, Loss: 2.08\n",
      "UPDATE - Epoch: 356, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 356, Loss: 2.08\n",
      "UPDATE - Epoch: 357, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 357, Loss: 2.08\n",
      "UPDATE - Epoch: 358, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 358, Loss: 2.08\n",
      "UPDATE - Epoch: 359, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 359, Loss: 2.08\n",
      "UPDATE - Epoch: 360, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 360, Loss: 2.08\n",
      "UPDATE - Epoch: 361, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 361, Loss: 2.08\n",
      "UPDATE - Epoch: 362, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 362, Loss: 2.08\n",
      "UPDATE - Epoch: 363, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 363, Loss: 2.08\n",
      "UPDATE - Epoch: 364, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 364, Loss: 2.08\n",
      "UPDATE - Epoch: 365, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 365, Loss: 2.08\n",
      "UPDATE - Epoch: 366, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 366, Loss: 2.08\n",
      "UPDATE - Epoch: 367, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 367, Loss: 2.08\n",
      "UPDATE - Epoch: 368, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 368, Loss: 2.08\n",
      "UPDATE - Epoch: 369, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 369, Loss: 2.08\n",
      "UPDATE - Epoch: 370, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 370, Loss: 2.08\n",
      "UPDATE - Epoch: 371, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 371, Loss: 2.08\n",
      "UPDATE - Epoch: 372, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 372, Loss: 2.08\n",
      "UPDATE - Epoch: 373, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 373, Loss: 2.08\n",
      "UPDATE - Epoch: 374, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 374, Loss: 2.08\n",
      "UPDATE - Epoch: 375, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 375, Loss: 2.08\n",
      "UPDATE - Epoch: 376, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 376, Loss: 2.08\n",
      "UPDATE - Epoch: 377, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 377, Loss: 2.08\n",
      "UPDATE - Epoch: 378, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 378, Loss: 2.08\n",
      "UPDATE - Epoch: 379, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 379, Loss: 2.08\n",
      "UPDATE - Epoch: 380, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 380, Loss: 2.08\n",
      "UPDATE - Epoch: 381, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 381, Loss: 2.08\n",
      "UPDATE - Epoch: 382, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 382, Loss: 2.08\n",
      "UPDATE - Epoch: 383, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 383, Loss: 2.08\n",
      "UPDATE - Epoch: 384, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 384, Loss: 2.08\n",
      "UPDATE - Epoch: 385, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 385, Loss: 2.08\n",
      "UPDATE - Epoch: 386, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 386, Loss: 2.08\n",
      "UPDATE - Epoch: 387, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 387, Loss: 2.08\n",
      "UPDATE - Epoch: 388, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 388, Loss: 2.08\n",
      "UPDATE - Epoch: 389, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 389, Loss: 2.08\n",
      "UPDATE - Epoch: 390, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 390, Loss: 2.08\n",
      "UPDATE - Epoch: 391, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 391, Loss: 2.08\n",
      "UPDATE - Epoch: 392, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 392, Loss: 2.08\n",
      "UPDATE - Epoch: 393, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 393, Loss: 2.08\n",
      "UPDATE - Epoch: 394, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 394, Loss: 2.08\n",
      "UPDATE - Epoch: 395, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 395, Loss: 2.08\n",
      "UPDATE - Epoch: 396, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 396, Loss: 2.08\n",
      "UPDATE - Epoch: 397, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 397, Loss: 2.08\n",
      "UPDATE - Epoch: 398, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 398, Loss: 2.08\n",
      "UPDATE - Epoch: 399, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 399, Loss: 2.08\n",
      "UPDATE - Epoch: 400, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 400, Loss: 2.08\n",
      "UPDATE - Epoch: 401, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 401, Loss: 2.08\n",
      "UPDATE - Epoch: 402, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 402, Loss: 2.08\n",
      "UPDATE - Epoch: 403, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 403, Loss: 2.08\n",
      "UPDATE - Epoch: 404, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 404, Loss: 2.08\n",
      "UPDATE - Epoch: 405, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 405, Loss: 2.08\n",
      "UPDATE - Epoch: 406, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 406, Loss: 2.08\n",
      "UPDATE - Epoch: 407, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 407, Loss: 2.08\n",
      "UPDATE - Epoch: 408, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 408, Loss: 2.08\n",
      "UPDATE - Epoch: 409, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 409, Loss: 2.08\n",
      "UPDATE - Epoch: 410, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 410, Loss: 2.08\n",
      "UPDATE - Epoch: 411, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 411, Loss: 2.08\n",
      "UPDATE - Epoch: 412, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 412, Loss: 2.08\n",
      "UPDATE - Epoch: 413, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 413, Loss: 2.08\n",
      "UPDATE - Epoch: 414, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 414, Loss: 2.08\n",
      "UPDATE - Epoch: 415, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 415, Loss: 2.08\n",
      "UPDATE - Epoch: 416, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 416, Loss: 2.08\n",
      "UPDATE - Epoch: 417, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 417, Loss: 2.08\n",
      "UPDATE - Epoch: 418, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 418, Loss: 2.08\n",
      "UPDATE - Epoch: 419, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 419, Loss: 2.08\n",
      "UPDATE - Epoch: 420, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 420, Loss: 2.08\n",
      "UPDATE - Epoch: 421, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 421, Loss: 2.08\n",
      "UPDATE - Epoch: 422, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 422, Loss: 2.08\n",
      "UPDATE - Epoch: 423, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 423, Loss: 2.08\n",
      "UPDATE - Epoch: 424, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 424, Loss: 2.08\n",
      "UPDATE - Epoch: 425, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 425, Loss: 2.08\n",
      "UPDATE - Epoch: 426, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 426, Loss: 2.08\n",
      "UPDATE - Epoch: 427, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 427, Loss: 2.08\n",
      "UPDATE - Epoch: 428, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 428, Loss: 2.08\n",
      "UPDATE - Epoch: 429, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 429, Loss: 2.08\n",
      "UPDATE - Epoch: 430, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 430, Loss: 2.08\n",
      "UPDATE - Epoch: 431, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 431, Loss: 2.08\n",
      "UPDATE - Epoch: 432, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 432, Loss: 2.08\n",
      "UPDATE - Epoch: 433, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 433, Loss: 2.08\n",
      "UPDATE - Epoch: 434, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 434, Loss: 2.08\n",
      "UPDATE - Epoch: 435, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 435, Loss: 2.08\n",
      "UPDATE - Epoch: 436, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 436, Loss: 2.08\n",
      "UPDATE - Epoch: 437, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 437, Loss: 2.08\n",
      "UPDATE - Epoch: 438, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 438, Loss: 2.08\n",
      "UPDATE - Epoch: 439, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 439, Loss: 2.08\n",
      "UPDATE - Epoch: 440, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 440, Loss: 2.08\n",
      "UPDATE - Epoch: 441, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 441, Loss: 2.08\n",
      "UPDATE - Epoch: 442, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 442, Loss: 2.08\n",
      "UPDATE - Epoch: 443, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 443, Loss: 2.08\n",
      "UPDATE - Epoch: 444, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 444, Loss: 2.08\n",
      "UPDATE - Epoch: 445, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 445, Loss: 2.08\n",
      "UPDATE - Epoch: 446, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 446, Loss: 2.08\n",
      "UPDATE - Epoch: 447, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 447, Loss: 2.08\n",
      "UPDATE - Epoch: 448, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 448, Loss: 2.08\n",
      "UPDATE - Epoch: 449, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 449, Loss: 2.08\n",
      "UPDATE - Epoch: 450, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 450, Loss: 2.08\n",
      "UPDATE - Epoch: 451, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 451, Loss: 2.08\n",
      "UPDATE - Epoch: 452, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 452, Loss: 2.08\n",
      "UPDATE - Epoch: 453, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 453, Loss: 2.08\n",
      "UPDATE - Epoch: 454, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 454, Loss: 2.08\n",
      "UPDATE - Epoch: 455, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 455, Loss: 2.08\n",
      "UPDATE - Epoch: 456, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 456, Loss: 2.08\n",
      "UPDATE - Epoch: 457, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 457, Loss: 2.08\n",
      "UPDATE - Epoch: 458, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 458, Loss: 2.08\n",
      "UPDATE - Epoch: 459, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 459, Loss: 2.08\n",
      "UPDATE - Epoch: 460, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 460, Loss: 2.08\n",
      "UPDATE - Epoch: 461, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 461, Loss: 2.08\n",
      "UPDATE - Epoch: 462, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 462, Loss: 2.08\n",
      "UPDATE - Epoch: 463, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 463, Loss: 2.08\n",
      "UPDATE - Epoch: 464, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 464, Loss: 2.08\n",
      "UPDATE - Epoch: 465, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 465, Loss: 2.08\n",
      "UPDATE - Epoch: 466, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 466, Loss: 2.08\n",
      "UPDATE - Epoch: 467, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 467, Loss: 2.08\n",
      "UPDATE - Epoch: 468, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 468, Loss: 2.08\n",
      "UPDATE - Epoch: 469, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 469, Loss: 2.08\n",
      "UPDATE - Epoch: 470, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 470, Loss: 2.08\n",
      "UPDATE - Epoch: 471, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 471, Loss: 2.08\n",
      "UPDATE - Epoch: 472, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 472, Loss: 2.08\n",
      "UPDATE - Epoch: 473, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 473, Loss: 2.08\n",
      "UPDATE - Epoch: 474, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 474, Loss: 2.08\n",
      "UPDATE - Epoch: 475, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 475, Loss: 2.08\n",
      "UPDATE - Epoch: 476, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 476, Loss: 2.08\n",
      "UPDATE - Epoch: 477, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 477, Loss: 2.08\n",
      "UPDATE - Epoch: 478, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 478, Loss: 2.08\n",
      "UPDATE - Epoch: 479, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 479, Loss: 2.08\n",
      "UPDATE - Epoch: 480, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 480, Loss: 2.08\n",
      "UPDATE - Epoch: 481, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 481, Loss: 2.08\n",
      "UPDATE - Epoch: 482, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 482, Loss: 2.08\n",
      "UPDATE - Epoch: 483, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 483, Loss: 2.08\n",
      "UPDATE - Epoch: 484, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 484, Loss: 2.08\n",
      "UPDATE - Epoch: 485, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 485, Loss: 2.08\n",
      "UPDATE - Epoch: 486, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 486, Loss: 2.08\n",
      "UPDATE - Epoch: 487, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 487, Loss: 2.08\n",
      "UPDATE - Epoch: 488, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 488, Loss: 2.08\n",
      "UPDATE - Epoch: 489, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 489, Loss: 2.08\n",
      "UPDATE - Epoch: 490, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 490, Loss: 2.08\n",
      "UPDATE - Epoch: 491, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 491, Loss: 2.08\n",
      "UPDATE - Epoch: 492, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 492, Loss: 2.08\n",
      "UPDATE - Epoch: 493, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 493, Loss: 2.08\n",
      "UPDATE - Epoch: 494, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 494, Loss: 2.08\n",
      "UPDATE - Epoch: 495, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 495, Loss: 2.08\n",
      "UPDATE - Epoch: 496, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 496, Loss: 2.08\n",
      "UPDATE - Epoch: 497, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 497, Loss: 2.08\n",
      "UPDATE - Epoch: 498, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 498, Loss: 2.08\n",
      "UPDATE - Epoch: 499, Train Acc: 50.91% (loss: 2.08), Test Acc:  50.39% (loss: 2.08)\n",
      "Epoch: 499, Loss: 2.08\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import json\n",
    "import time\n",
    "\n",
    "# nice file name including the date to store accuracy data\n",
    "date_str = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# create the model\n",
    "model = SentimentAnalysisModel(\n",
    "    vocab_size=vocab_size,\n",
    "    emb_dim=30,\n",
    "    hidden_size=40,\n",
    "    n_rnn_layers=1,\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "subset = batch_size * 3\n",
    "\n",
    "train_data = train_data.to(device)[:subset]\n",
    "train_labels = train_labels.to(device)[:subset]\n",
    "train_lengths = train_lengths.to(device)[:subset]\n",
    "\n",
    "test_data = test_data.to(device)[:subset]\n",
    "test_labels = test_labels.to(device)[:subset]\n",
    "test_lengths = test_lengths.to(device)[:subset]\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "eval_interval = 1\n",
    "\n",
    "acc_best = 0\n",
    "acc_data = []\n",
    "\n",
    "# train the model\n",
    "for epoch in range(500):\n",
    "    if epoch % eval_interval == 0:\n",
    "        train_loss, train_correct, train_total = calculate_accuracy(\n",
    "            model, train_data, train_labels, train_lengths, batch_size\n",
    "        )\n",
    "        test_loss, test_correct, test_total = calculate_accuracy(\n",
    "            model, test_data, test_labels, test_lengths, batch_size\n",
    "        )\n",
    "        torch.save(model.state_dict(), f\"models/rnn_{date_str}_latest.pt\")\n",
    "\n",
    "        test_acc = test_correct / test_total * 100\n",
    "        train_acc = train_correct / train_total * 100\n",
    "\n",
    "        if test_acc > acc_best:\n",
    "            torch.save(model.state_dict(), f\"models/rnn_{date_str}_best.pt\")\n",
    "            acc_best = test_acc\n",
    "\n",
    "        print(\n",
    "            f\"UPDATE - Epoch: {epoch}, \"\n",
    "            f\"Train Acc: {train_acc:0.2f}% (loss: {train_loss:0.2f}), \"\n",
    "            f\"Test Acc: {test_acc: 0.2f}% (loss: {test_loss:0.2f})\"\n",
    "        )\n",
    "        acc_data.append(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"train_acc\": train_acc,\n",
    "                \"test_acc\": test_acc,\n",
    "                \"train_loss\": train_loss.item(),\n",
    "                \"test_loss\": test_loss.item(),\n",
    "            }\n",
    "        )\n",
    "        with open(f\"models/rnn_{date_str}_acc.json\", \"w\") as f:\n",
    "            json.dump(acc_data, f, indent=4)\n",
    "\n",
    "    cum_loss = 0\n",
    "\n",
    "    for i in range(0, len(train_data), batch_size):\n",
    "        training_data_batch = train_data[i : i + batch_size]\n",
    "        training_labels_batch = train_labels[i : i + batch_size]\n",
    "        training_lengths_batch = train_lengths[i : i + batch_size]\n",
    "\n",
    "        # forward pass\n",
    "        optimizer.zero_grad()\n",
    "        output = model(training_data_batch, lengths=training_lengths_batch)\n",
    "\n",
    "        loss = nn.functional.cross_entropy(output, training_labels_batch)\n",
    "        loss.backward()\n",
    "        # During training, after loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "        cum_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch: {epoch}, Loss: {cum_loss:0.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83f8aac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d721009",
   "metadata": {},
   "source": [
    "## Loading in latest model to check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03453a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the latest model\n",
    "loaded_model = SentimentAnalysisModel(vocab_size=vocab_size)\n",
    "loaded_model.load_state_dict(torch.load(\"models/rnn_latest.pt\"))\n",
    "loaded_model.to(device)\n",
    "\n",
    "test_data = test_data.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "\n",
    "test_stats = calculate_accuracy(loaded_model, test_data, test_labels, test_lengths, batch_size)\n",
    "train_stats = calculate_accuracy(loaded_model, train_data, train_labels, train_lengths, batch_size)\n",
    "\n",
    "\n",
    "print(f\"Test Loss: {test_stats[0]}, Test Accuracy: {test_stats[1]/test_stats[2]*100: .2f}\")\n",
    "print(f\"Train Loss: {train_stats[0]}, Train Accuracy: {train_stats[1]/train_stats[2]*100: .2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
