{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e3a6cb3-d272-44ec-a666-ed634b9486f1",
   "metadata": {},
   "source": [
    "# Building a Deep Neural Net for Sentiment Analysis on IMDb Reviews\n",
    "\n",
    "## 1. Data collection and preprocessing\n",
    "- Collect a dataset of IMDb reviews\n",
    "- Preprocess the text data (tokenization, lowercasing, removing special characters, etc.)\n",
    "- Split the dataset into training, validation, and test sets\n",
    "\n",
    "## 2. **Model selection and architecture**\n",
    "- Research different types of deep learning models (**RNN**, LSTM, GRU, CNN, Transformer)\n",
    "- Decide on a model architecture\n",
    "- Experiment with pre-trained models (BERT, GPT, RoBERTa) for fine-tuning\n",
    "\n",
    "## 3. Model training and hyperparameter tuning\n",
    "- Set up a training loop\n",
    "- Use backpropagation to update the model's weights based on the loss function\n",
    "- Experiment with different hyperparameters (learning rate, batch size, dropout rate, etc.) and optimization algorithms (Adam, RMSprop, etc.)\n",
    "- Monitor performance on the validation set during training\n",
    "\n",
    "## 4. Model evaluation and refinement\n",
    "- Evaluate the model on the test set using relevant metrics (accuracy, F1 score, precision, recall, etc.)\n",
    "- Identify areas for improvement and iterate on the model architecture, training process, or preprocessing techniques\n",
    "\n",
    "## 5. \"Extra for experts\" ideas\n",
    "- Handle class imbalance (oversampling, undersampling, or SMOTE)\n",
    "- Experiment with different word embeddings (Word2Vec, GloVe, FastText) or contextual embeddings (ELMo, BERT)\n",
    "- Explore advanced model architectures (multi-head attention, capsule networks, memory-augmented networks)\n",
    "- Investigate transfer learning or multi-task learning\n",
    "- Conduct error analysis to understand and address specific issues\n",
    "- Develop a user interface or API for your sentiment analysis model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4e9b2ba-e5d6-453c-aea1-d445c4249e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenizers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        emb_dim: int = 300,\n",
    "        hidden_size: int = 400,\n",
    "        n_rnn_layers: int = 5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=emb_dim,\n",
    "        )\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=emb_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=n_rnn_layers,\n",
    "        )\n",
    "\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, 2),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, lengths: torch.Tensor):\n",
    "        # x shape: (B, L)\n",
    "        # convert token indices to embedding values\n",
    "        x = self.emb(x)\n",
    "        # x shape: (B, L, Emb dim)\n",
    "\n",
    "        x = x.transpose(0, 1)\n",
    "        # x shape: (L, B, Emb dim)\n",
    "\n",
    "        # pack the sequence\n",
    "        x = pack_padded_sequence(x, lengths, enforce_sorted=False)\n",
    "\n",
    "        # run the rnn, only taking the final rnn hidden state from the last layer\n",
    "        # TODO: understand the difference between the two outputs more\n",
    "        _, x = self.rnn(x)\n",
    "        # x shape: (B, n_rnn_layers, Hidden size?)\n",
    "        \n",
    "        # take only the last layer\n",
    "        x = x[-1, :, :]\n",
    "        # x shape: (B, Hidden size?)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        # x shape: (B, 2)\n",
    "\n",
    "        return F.softmax(F.relu(x), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37b1b78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import Dataset\n",
    "\n",
    "# load in tokenized data\n",
    "data_dict = torch.load(\"data/imdb_data.pt\")\n",
    "data = data_dict[\"reviews\"]\n",
    "labels = data_dict[\"labels\"]\n",
    "lengths = data_dict[\"lengths\"]\n",
    "\n",
    "# split into train and test by 80:20\n",
    "train_data = data[:int(len(data) * 0.8)]\n",
    "train_labels = labels[:int(len(data) * 0.8)]\n",
    "train_lengths = lengths[:int(len(data) * 0.8)]\n",
    "\n",
    "test_data = data[int(len(data) * 0.8):]\n",
    "test_labels = labels[int(len(data) * 0.8):]\n",
    "test_lengths = lengths[int(len(data) * 0.8):]\n",
    "\n",
    "\n",
    "# load in tokenizer\n",
    "tokenizer = tokenizers.Tokenizer.from_file(\"models/tokenizer.json\")\n",
    "vocab_size = tokenizer.get_vocab_size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "885a232e",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb64173b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:11<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 36.74216842651367, Accuracy:  49.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [01:07<00:00,  1.56it/s]\n",
      "100%|██████████| 105/105 [01:07<00:00,  1.57it/s]\n",
      "100%|██████████| 105/105 [01:07<00:00,  1.57it/s]\n",
      "100%|██████████| 105/105 [01:07<00:00,  1.57it/s]\n",
      "100%|██████████| 105/105 [01:07<00:00,  1.57it/s]\n",
      "100%|██████████| 53/53 [00:11<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss: 36.633888244628906, Accuracy:  52.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [01:07<00:00,  1.57it/s]\n",
      "100%|██████████| 105/105 [01:07<00:00,  1.57it/s]\n",
      "100%|██████████| 105/105 [01:07<00:00,  1.57it/s]\n",
      "100%|██████████| 105/105 [01:07<00:00,  1.57it/s]\n",
      "100%|██████████| 105/105 [01:07<00:00,  1.57it/s]\n",
      "100%|██████████| 53/53 [00:11<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 36.465213775634766, Accuracy:  55.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 17/105 [00:11<00:59,  1.49it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m training_labels_batch \u001b[39m=\u001b[39m train_labels[i:i\u001b[39m+\u001b[39mbatch_size]\n\u001b[1;32m     46\u001b[0m training_lengths_batch \u001b[39m=\u001b[39m train_lengths[i:i\u001b[39m+\u001b[39mbatch_size]\n\u001b[0;32m---> 48\u001b[0m output \u001b[39m=\u001b[39m model(training_data_batch, lengths\u001b[39m=\u001b[39;49mtraining_lengths_batch)\n\u001b[1;32m     50\u001b[0m \u001b[39m# forward pass\u001b[39;00m\n\u001b[1;32m     51\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/source/pytorch_hello_worlds/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[1], line 42\u001b[0m, in \u001b[0;36mRNNModel.forward\u001b[0;34m(self, x, lengths)\u001b[0m\n\u001b[1;32m     38\u001b[0m x \u001b[39m=\u001b[39m pack_padded_sequence(x, lengths, enforce_sorted\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     40\u001b[0m \u001b[39m# run the rnn, only taking the final rnn hidden state from the last layer\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39m# TODO: understand the difference between the two outputs more\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m _, x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrnn(x)\n\u001b[1;32m     43\u001b[0m \u001b[39m# x shape: (B, n_rnn_layers, Hidden size?)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \n\u001b[1;32m     45\u001b[0m \u001b[39m# take only the last layer\u001b[39;00m\n\u001b[1;32m     46\u001b[0m x \u001b[39m=\u001b[39m x[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :, :]\n",
      "File \u001b[0;32m~/source/pytorch_hello_worlds/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/source/pytorch_hello_worlds/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:518\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    517\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mRNN_TANH\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 518\u001b[0m         result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mrnn_tanh(\u001b[39minput\u001b[39;49m, batch_sizes, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    519\u001b[0m                               \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[1;32m    520\u001b[0m                               \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional)\n\u001b[1;32m    521\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    522\u001b[0m         result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mrnn_relu(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m    523\u001b[0m                               \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining,\n\u001b[1;32m    524\u001b[0m                               \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "batch_size = 256 + 128\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# create the model\n",
    "model = RNNModel(vocab_size=vocab_size)\n",
    "model = model.to(device)\n",
    "\n",
    "train_data = train_data.to(device)\n",
    "train_labels = train_labels.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "eval_interval = 5\n",
    "\n",
    "# train the model\n",
    "for epoch in range(500):\n",
    "    if epoch % eval_interval == 0:\n",
    "        # calculate overall loss (need batching for memory reasons)\n",
    "        loss = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i in tqdm(range(0, len(train_data), 2*batch_size)):\n",
    "                training_data_batch = train_data[i:i+batch_size]\n",
    "                training_labels_batch = train_labels[i:i+batch_size]\n",
    "                training_lengths_batch = train_lengths[i:i+batch_size]\n",
    "\n",
    "                output = model(training_data_batch, lengths=training_lengths_batch)\n",
    "                ## Calculate correct predictions\n",
    "                _, y_predicted = torch.max(output, 1)\n",
    "                _, y = torch.max(training_labels_batch, 1)\n",
    "                total += training_labels_batch.size(0)\n",
    "                correct += (y_predicted == y).sum().item()\n",
    "                loss += nn.functional.cross_entropy(output, training_labels_batch)\n",
    "        \n",
    "        print(f\"Epoch: {epoch}, Loss: {loss.item()}, Accuracy: {correct/total*100: .2f}\")\n",
    "    \n",
    "    for i in tqdm(range(0, len(train_data), batch_size)):\n",
    "        training_data_batch = train_data[i:i+batch_size]\n",
    "        training_labels_batch = train_labels[i:i+batch_size]\n",
    "        training_lengths_batch = train_lengths[i:i+batch_size]\n",
    "\n",
    "        output = model(training_data_batch, lengths=training_lengths_batch)\n",
    "\n",
    "        # forward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss = nn.functional.cross_entropy(output, training_labels_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
