{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e1510dc1-66eb-42fe-8b88-7044a883a747",
   "metadata": {},
   "source": [
    "Useful resources\n",
    "* [Andrej Karpathy Let's Build GPT](https://www.youtube.com/watch?v=kCc8FmEb1nY)\n",
    "* [PyTorch-Transformers](https://pytorch.org/hub/huggingface_pytorch-transformers/) (I think this got spun out into the transformers package)\n",
    "* [Actual tranformers in pytorch](https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html)\n",
    "* [In depth Sentiment analysis w transformers on kaggle](https://www.kaggle.com/code/emirkocak/in-depth-series-sentiment-analysis-w-transformers)\n",
    "* Some papers\n",
    "    * [Text Sentiment Analysis Based on Transformer and Augmentation](https://www.frontiersin.org/articles/10.3389/fpsyg.2022.906061/full)\n",
    "    * [Transformer-based deep learning models for the sentiment analysis of social media data](https://www.sciencedirect.com/science/article/pii/S2590005622000224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "149a9109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class SentimentAnalysis(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        embedding_dim: int = 128,\n",
    "        num_classes: int = 2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb = nn.Embedding(vocab_size, embedding_dim=embedding_dim)\n",
    "        self.transformer = nn.Transformer(embedding_dim, 8, 4, 4, 4, 0.1)\n",
    "\n",
    "        self.fc = nn.Linear(embedding_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = self.transformer(x, x)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = x[:, -1]\n",
    "        x = self.fc(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "732ecfe8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtut\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msentiment_analysis\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhelpers\u001b[39;00m \u001b[39mimport\u001b[39;00m load_sentiment_data, load_tokenizer, calc_accuracy\n\u001b[1;32m      3\u001b[0m (\n\u001b[1;32m      4\u001b[0m     train_data,\n\u001b[1;32m      5\u001b[0m     train_labels,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     test_lengths,\n\u001b[1;32m     10\u001b[0m ) \u001b[39m=\u001b[39m load_sentiment_data()\n\u001b[1;32m     12\u001b[0m tokenizer \u001b[39m=\u001b[39m load_tokenizer()\n",
      "File \u001b[0;32m~/source/pytorch_tut/tut/sentiment_analysis/../../tut/sentiment_analysis/helpers.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtokenizers\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[1;32m      7\u001b[0m _file_dir \u001b[39m=\u001b[39m Path(\u001b[39m__file__\u001b[39m)\u001b[39m.\u001b[39mresolve()\u001b[39m.\u001b[39mparent\n\u001b[1;32m     10\u001b[0m _DEFAULT_IMDB_DATA_PATH \u001b[39m=\u001b[39m _file_dir \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mimdb_data.pt\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "from tut.sentiment_analysis.helpers import load_sentiment_data, load_tokenizer, calc_accuracy\n",
    "\n",
    "(\n",
    "    train_data,\n",
    "    train_labels,\n",
    "    train_lengths,\n",
    "    test_data,\n",
    "    test_labels,\n",
    "    test_lengths,\n",
    ") = load_sentiment_data()\n",
    "\n",
    "tokenizer = load_tokenizer()\n",
    "vocab_size = tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80f4634",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
