# JeromeBot: Training an LLM on my DMs

* Using facebook data request
* Following these resources:
    * [HuggingFace tutorial](https://huggingface.co/docs/transformers/training)
    * [Another HuggingFace tut](https://huggingface.co/docs/transformers/v4.15.0/custom_datasets)
    * [Fine-tuning 20B LLMs with RLHF on a 24GB consumer GPU](https://huggingface.co/blog/trl-peft)
    * [Model parallelism](https://huggingface.co/docs/transformers/v4.17.0/en/parallelism)
    * [Processing Data for LLMs](https://wandb.ai/wandb_gen/llm-data-processing/reports/Processing-Data-for-Large-Language-Models--VmlldzozMDg4MTM2)
    * [GPT-2 data preparation](https://rowlando13.medium.com/everything-gpt-2-4-data-preparation-514cb62f9f3b)
    * [Dataset engineering for LLM finetuning](https://www.flowrite.com/blog/dataset-engineering-llm-finetuning)
    * [Causal language modeling](https://huggingface.co/docs/transformers/tasks/language_modeling)
